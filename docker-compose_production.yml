version: "3.5"
services:
  rabbit:
    image: rabbitmq:3.8.5-management
    ports:
      - '15673:15672' # in case user has rabbitMQ installed on host
    environment:
      - RABBITMQ_DEFAULT_USER=axiome3
      - RABBITMQ_DEFAULT_PASS=neufeld
      - RABBITMQ_DEFAULT_VHOST=axiome3_host

  backend:
    build:
      context: ./backend
      dockerfile: dev.Dockerfile
      args:
        - QIIME2_RELEASE=2020.6
        - CLASSIFIER_GDRIVE_ID=12jug9XZcbUefevtTnENGudjGqaAL0LCo
    command: ["python", "server.py", '--py-autoreload', '1']
    volumes:
      - ./backend:/backend
      - /:/hostfs:ro # Assumes host root is '/'
      - ./output:/output # Stores all the output to this directory
      - ./log:/log # For logging
      - input:/input # Named volume
      - pipeline_volume:/pipeline/AXIOME3
    ports:
      - '5000'
    environment:
      - FLASK_ENV=development
      - FLASK_APP=AXIOME3_app/app
      - PYTHONPATH=/pipeline/AXIOME3 # Add AXIOME3 pipeline to PYTHONPATH
      - LUIGI_CONFIG_PATH=/pipeline/AXIOME3/configuration/luigi.cfg

  pipeline_worker:
    build:
      context: ./backend
      dockerfile: dev.Dockerfile
      args:
        - QIIME2_RELEASE=2020.6
        - CLASSIFIER_GDRIVE_ID=12jug9XZcbUefevtTnENGudjGqaAL0LCo
    command: "celery worker -A AXIOME3_app.celery_app:app --concurrency=1 -n worker1@%h -Q pipeline --loglevel=INFO"
    volumes:
      - /:/hostfs:ro # Assumes host root is '/'
      - ./backend:/backend
      - ./output:/output # Stores all the output to this directory
      - ./log:/log # For logging
      - input:/input # Named volume
      - pipeline_volume:/pipeline/AXIOME3
    environment:
      - PYTHONPATH=/pipeline/AXIOME3 # Add AXIOME3 pipeline to PYTHONPATH
      - LUIGI_CONFIG_PATH=/pipeline/AXIOME3/configuration/luigi.cfg

  extension_worker:
    build:
      context: ./backend
      dockerfile: dev.Dockerfile
      args:
        - QIIME2_RELEASE=2020.6
        - CLASSIFIER_GDRIVE_ID=12jug9XZcbUefevtTnENGudjGqaAL0LCo
    command: "celery worker -A AXIOME3_app.celery_app:app --concurrency=1 -n worker2@%h -Q extension --loglevel=INFO"
    volumes:
      - /:/hostfs:ro # Assumes host root is '/'
      - ./backend:/backend
      - ./output:/output # Stores all the output to this directory
      - ./log:/log # For logging
      - input:/input # Named volume
      - pipeline_volume:/pipeline/AXIOME3
    environment:
      - PYTHONPATH=/pipeline/AXIOME3 # Add AXIOME3 pipeline to PYTHONPATH

  app:
    build:
      context: .
      dockerfile: production.Dockerfile
    volumes:
      - ./nginx/prod/nginx.conf:/etc/nginx/nginx.conf
    ports:
      - '8080:80'
    depends_on:
      - backend
    environment:
      - PORT=8080
    command: nginx -g "daemon off";

volumes:
  input:
  node_module:
  pipeline_volume: